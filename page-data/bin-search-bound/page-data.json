{"componentChunkName":"component---src-templates-blog-template-js","path":"/bin-search-bound/","result":{"data":{"cur":{"id":"54bfcba0-c3f2-59e2-ad81-8f56a2e38c26","html":"<p>이진탐색의 응용 버전으로 상/하한선을 찾는 알고리즘이다. 이를 응용한 <a href=\"https://www.acmicpc.net/problem/10816\">문제</a>를 풀면서 배운 개념을 정리해둔다. <br></p>\n<p>이진탐색을 사용하면 모든 요소들을 다 방문하면서 탐색하는 것보다 훨씬 더 효율적으로 원하는 요소를 탐색할 수 있다. 하지만 이진탐색의 경우, <u>중복되지 않은 값이 주어진 경우</u>이거나, <u>해당 요소의 존재 여부</u>만을 가리기 위해서 일 경우에만 사용이 가능하다. 위의 문제의 경우, 중복되는 값들이 존재하며 그 값들이 총 몇개가 있는지도 확인할 수 있어야 하기 때문에 일반적인 이진탐색을 통해서는 답을 도출할 수 없다. 그래서 찾은 알고리즘 <mark>Upper Bound</mark> 와 <mark>Lower Bound</mark> 알고리즘 이다. <strong>이진탐색에서 살짝 변형되어서 중복된 자료가 있을 때 유용하게 탐색할 수 있는 알고리즘</strong>이다. <br></p>\n<p>아래 그림을 보면 lower bound와 upper bound에 대해서 더 잘 이해할 수 있다. <br></p>\n<p><img src=\"https://user-images.githubusercontent.com/63405904/111030306-c4d70300-8444-11eb-8b82-7ad2c3cc0ec1.png\" alt=\"image\"></p>\n<h2 id=\"upper-bound-algorithm\" style=\"position:relative;\"><a href=\"#upper-bound-algorithm\" aria-label=\"upper bound algorithm permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Upper Bound Algorithm</h2>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">> Upper Bound Theory:\n\tK 값보다 큰 값(>)이 처음 나오는 위치를 리턴해주는 알고리즘. </code></pre></div>\n<p>구현은 이진 탐색과 매우 유사하지만 약간의 변형이 있다. <br></p>\n<ol>\n<li><strong>탐색의 범위를 크기가 n일 때:</strong> index만큼인 n-1까지 탐색하는 것이 아니라, n까지 탐색해야 함.</li>\n<li><strong>탐색하는 숫자 k를 찾았거나, mid 값보다 k가 작을 경우:</strong>  해당 값이나 위치를 return하는 것이 아니라, 중간 값 이후부터 분할한 오른쪽 부분을 재 탐색함. </li>\n<li><strong>탐색하는 숫자 k보다 mid에 있는 값이 클 경우:</strong> 본래 mid를 제외한 start~mid-1까지를 탐색했으나, 여기서는 start~mid 탐색해 mid값을 재포함 함. </li>\n</ol>\n<p>여기서 1번을 시행하는 이유는 만약 배열에 있는 모든 요소, 혹은 마지막 요소보다 큰 값에 대해서 return 해야할 경우, 배열의 크기 만큼을 리턴해야 하므로 end 요소에 이진 탐색처럼 <code class=\"language-text\">array.length-1</code>이 아닌 <code class=\"language-text\">array.length</code>가 들어가야 한다. <br></p>\n<p>2번의 경우에는 해당 값 k를 찾았을 때도, <em><u>k보다 큰 값이 처음 등장하는 위치</u></em> 를 찾아야 하기 때문에, 해당 다음 위치부터 end index에 대해서 마지막 하나 남을 때까지 재탐색 해야 한다. <br></p>\n<p>3번의 경우 mid 인덱스를 재포함하는 이유는 해당 mid에 있는 값이 upper bound 일 수 있으나, 탐색 숫자 k보다 <u>큰 첫번째 숫자임을 보장할 수 없기 때문에</u> 탐색을 이어서 진행하는 것이다. <br></p>\n<p><strong>코드:</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"java\"><pre class=\"language-java\"><code class=\"language-java\"><span class=\"token keyword\">static</span> <span class=\"token keyword\">int</span> <span class=\"token function\">searchUpper</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> start<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> end<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> num<span class=\"token punctuation\">)</span><span class=\"token punctuation\">{</span>\n  <span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span>start<span class=\"token operator\">>=</span>end<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> start<span class=\"token punctuation\">;</span>\n  \n  <span class=\"token keyword\">int</span> mid <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>start<span class=\"token operator\">+</span>end<span class=\"token punctuation\">)</span><span class=\"token operator\">/</span><span class=\"token number\">2</span><span class=\"token punctuation\">;</span>\n  \n  <span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span>num_list<span class=\"token punctuation\">[</span>mid<span class=\"token punctuation\">]</span><span class=\"token operator\">&lt;=</span>num<span class=\"token punctuation\">)</span><span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">return</span> <span class=\"token function\">searchUpper</span><span class=\"token punctuation\">(</span>mid<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> end<span class=\"token punctuation\">,</span> num<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span> <span class=\"token keyword\">else</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">return</span> <span class=\"token function\">searchUpper</span><span class=\"token punctuation\">(</span>start<span class=\"token punctuation\">,</span> mid<span class=\"token punctuation\">,</span> num<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<br>\n<h2 id=\"lower-bound-algorithm\" style=\"position:relative;\"><a href=\"#lower-bound-algorithm\" aria-label=\"lower bound algorithm permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Lower Bound Algorithm</h2>\n<p>Lower bound 또한 Upper bound와 매우 유사하게 진행되므로 위의 설명을 참고하면 된다. 다만 upper bound와 다르게 작용하는 부분은, 딱 한 부분이다. <br></p>\n<ul>\n<li>탐색하고 있는 k가 등장했을 때, upper bound 알고리즘에서는 mid+1 값부터 오른쪽 반을 탐색하였는데, lower bound 알고리즘에서는 mid를 포함시켜 왼쪽 반을 탐색하도록 한다. <br></li>\n</ul>\n<p>이 부분은 lower bound이 경우 숫자 k 가 처음 등장한 위치를 찾아야 하기 때문에 k 가 등장하더라도 그 이전에 k가 존재하지는 않는지 확인해야 하기 때문이다. <br></p>\n<br>\n<p><strong>코드:</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"java\"><pre class=\"language-java\"><code class=\"language-java\"><span class=\"token keyword\">static</span> <span class=\"token keyword\">int</span> <span class=\"token function\">searchLower</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> start<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> end<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> num<span class=\"token punctuation\">)</span><span class=\"token punctuation\">{</span>\n  <span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span>start<span class=\"token operator\">>=</span>end<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> start<span class=\"token punctuation\">;</span>\n  \n  <span class=\"token keyword\">int</span> mid <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>start<span class=\"token operator\">+</span>end<span class=\"token punctuation\">)</span><span class=\"token operator\">/</span><span class=\"token number\">2</span><span class=\"token punctuation\">;</span>\n  \n  <span class=\"token keyword\">if</span><span class=\"token punctuation\">(</span>num_list<span class=\"token punctuation\">[</span>mid<span class=\"token punctuation\">]</span><span class=\"token operator\">>=</span>num<span class=\"token punctuation\">)</span><span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">return</span> <span class=\"token function\">searchLower</span><span class=\"token punctuation\">(</span>start<span class=\"token punctuation\">,</span> mid<span class=\"token punctuation\">,</span> num<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span> <span class=\"token keyword\">else</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">return</span> <span class=\"token function\">searchLower</span><span class=\"token punctuation\">(</span>mid<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> end<span class=\"token punctuation\">,</span> num<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<br>\n<br>\n<p><strong><small>[참고 자료]: <a href=\"http://bajamircea.github.io/coding/cpp/2018/08/09/lower-bound.html\">http://bajamircea.github.io/coding/cpp/2018/08/09/lower-bound.html</a>, <a href=\"https://jackpot53.tistory.com/33#:~:text=lower%20bound%EB%8A%94%20%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%82%B4,%EB%A5%BC%20%EB%A6%AC%ED%84%B4%ED%95%B4%EC%A3%BC%EB%8A%94%20%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98%EC%9D%B4%EB%8B%A4.\">https://jackpot53.tistory.com/33#:~:text=lower%20bound%EB%8A%94%20%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%82%B4,%EB%A5%BC%20%EB%A6%AC%ED%84%B4%ED%95%B4%EC%A3%BC%EB%8A%94%20%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98%EC%9D%B4%EB%8B%A4.</a> </small></strong></p>\n<div class=\"table-of-contents\">\n<ul>\n<li><a href=\"#upper-bound-algorithm\">Upper Bound Algorithm</a></li>\n<li><a href=\"#lower-bound-algorithm\">Lower Bound Algorithm</a></li>\n</ul>\n</div>","excerpt":"이진탐색의 응용 버전으로 상/하한선을 찾는 알고리즘이다. 이를 응용한 문제를 풀면서 배운 개념을 정리해둔다.  이진탐색을 사용하면 모든 요소들을 다 방문하면서 탐색하는 것보다 훨씬 더 효율적으로 원하는 요소를 탐색할 수 있다. 하지만 이진탐색의 경우, 중복되지 않은 값이 주어진 경우이거나, 해당 요소의 존재 여부만을 가리기 위해서 일 경우에만 사용이 가능하다. 위의 문제의 경우, 중복되는 값들이 존재하며 그 값들이 총 몇개가 있는지도 확인할 수 있어야 하기 때문에 일반적인 이진탐색을 통해서는 답을 도출할 수 없다. 그래서 찾은 알고리즘 Upper Bound 와 Lower Bound 알고리즘 이다. 이진탐색에서 살짝 변형되어서 중복된 자료가 있을 때 유용하게 탐색할 수 있는 알고리즘이다.  아래 그림을 보면 lower bound와 upper bound에 대해서 더 잘 이해할 수 있다.  image Upper Bound Algorithm 구현은 이진 탐색과 매우 유사하지만 약간의 변형…","frontmatter":{"date":"September 04, 2020","title":"[알고리즘] 이진탐색 응용: UpperBound와 LowerBound","categories":"알고리즘","author":"코다","emoji":"🤹‍♀️"},"fields":{"slug":"/bin-search-bound/"}},"next":{"id":"0da8868f-8e99-5b04-8738-0846bdb6f9b8","html":"<p>이어서 딥러닝 영화 개인화 추천 모델을 구현하면서 구축한 딥러닝 협업 필터링 모델 부분에 대한 코드를 살펴보면서 딥러닝 전체적인 흐름에 대해서 짚어보자. 앞에서 언급했듯이 코드는 다음 <a href=\"https://jyoondev.tistory.com/65?category=823946\">링크</a>에서 참고하여 모델과 전체적인 데이터 처리를 진행했고, 이후에 학습된 output에 대한 데이터 및 결과 후처리는 추가 구현했다. 해당 부분은 다음 파트에 다루도록 하겠다. <br></p>\n<h2 id=\"모델-전체-코드\" style=\"position:relative;\"><a href=\"#%EB%AA%A8%EB%8D%B8-%EC%A0%84%EC%B2%B4-%EC%BD%94%EB%93%9C\" aria-label=\"모델 전체 코드 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>모델 전체 코드</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">NNCollabFiltering</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> num_users<span class=\"token punctuation\">,</span> num_items<span class=\"token punctuation\">,</span> emb_size<span class=\"token operator\">=</span><span class=\"token number\">100</span><span class=\"token punctuation\">,</span> n_hidden<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>NNCollabFiltering<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    self<span class=\"token punctuation\">.</span>user_emb <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Embedding<span class=\"token punctuation\">(</span>num_users<span class=\"token punctuation\">,</span> emb_size<span class=\"token punctuation\">)</span>\n    self<span class=\"token punctuation\">.</span>item_emb <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Embedding<span class=\"token punctuation\">(</span>num_items<span class=\"token punctuation\">,</span> emb_size<span class=\"token punctuation\">)</span>\n    self<span class=\"token punctuation\">.</span>lin1 <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>emb_size<span class=\"token operator\">*</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> n_hidden<span class=\"token punctuation\">)</span>\n    self<span class=\"token punctuation\">.</span>lin2 <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>n_hidden<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n    self<span class=\"token punctuation\">.</span>drop1 <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Dropout<span class=\"token punctuation\">(</span><span class=\"token number\">0.1</span><span class=\"token punctuation\">)</span>\n    \n  <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> u<span class=\"token punctuation\">,</span> v<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    U <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>user_emb<span class=\"token punctuation\">(</span>u<span class=\"token punctuation\">)</span>\n    V <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>item_emb<span class=\"token punctuation\">(</span>v<span class=\"token punctuation\">)</span>\n    x <span class=\"token operator\">=</span> F<span class=\"token punctuation\">.</span>relu<span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>cat<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>U<span class=\"token punctuation\">,</span> V<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> dim<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>drop1<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n    x <span class=\"token operator\">=</span> F<span class=\"token punctuation\">.</span>relu<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>lin1<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>lin2<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> x</code></pre></div>\n<br>\n<h2 id=\"step1-임베딩---nnembedding\" style=\"position:relative;\"><a href=\"#step1-%EC%9E%84%EB%B2%A0%EB%94%A9---nnembedding\" aria-label=\"step1 임베딩   nnembedding permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Step1. 임베딩 - nn.Embedding()</h2>\n<p>위 코드를 보면 먼저 User와 Item에 관한 임베딩으로 시작한다. 파이토치에서 임베딩 벡터를 사용하는 방법은 크게 두가지가 있는데 그 중 위의 <code class=\"language-text\">nn.Embedding()</code> 은 embedding layer를 만들어서 훈련 데이터로부터 처음부터 임베딩 벡터를 학습하는 방법이다. <br></p>\n<p>먼저 임베딩 층의 입력으로 사용하기 위해서는 정수 인코딩이 되어 있어야 한다. 즉 다음과 같은 단계를 따른다. <br></p>\n<blockquote>\n<p>어떤 단어 -> 고유한 정수로 인코딩 -> 임베딩 층을 통과 -> 밀집 벡터 </p>\n</blockquote>\n<p>즉, 고유한 정수 인코딩 값에 대해서 밀집 벡터(dense vector)를 맵핑해주는 것이다. 이 밀집 베터가 흔히 알고 있는 임베딩 벡터이다. 임베딩을 시킨다는 것은 어떠한 단어에 대한 고유 인코딩 정수값을 인덱스로 가지고 있는 룩업 테이블에서 해당 임베딩 벡터 값을 가져오는 것이다. 또한 <mark>이 테이블은 단어 집합만큼의 행을 가지고 있으므로 모든 단어들은 고유한 임베딩 벡터를 보유하게 된다.</mark> 이러한 벡터 값을 담고 있는 룩업 테이블을 생성하는 것이 <code class=\"language-text\">nn.Embedding()</code>의 역할이다. <br></p>\n<p><img src=\"https://user-images.githubusercontent.com/63405904/110482824-6bad5d80-812c-11eb-9da2-750e1946c80b.png\" alt=\"image\"></p>\n<p>위의 그림을 참고해보면 단어 ‘great’에 대한 임베딩 벡터가 4차원인 것을 확인할 수 있다. 해당 차원값은 parameter로 넘겨줄 수 있는 부분이다. 이렇게 생성된 임베딩 벡터는 모델의 입력이 되고, 역전파 과정을 거치면서 바로 이 임베딩 벡터값이 학습 되는 것이다. <br></p>\n<h3 id=\"-코드에서-임베딩\" style=\"position:relative;\"><a href=\"#-%EC%BD%94%EB%93%9C%EC%97%90%EC%84%9C-%EC%9E%84%EB%B2%A0%EB%94%A9\" aria-label=\" 코드에서 임베딩 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>> 코드에서 임베딩</h3>\n<p>위 코드에서 임베딩이 어떻게 이루어지고 있는지 살펴보자. 코드를 살펴보면 임베딩 관련한 부분에 다음과 같이 있다. <br></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\">#def __init__ 메소드 내: </span>\n  self<span class=\"token punctuation\">.</span>user_emb <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Embedding<span class=\"token punctuation\">(</span>num_users<span class=\"token punctuation\">,</span> emb_size<span class=\"token punctuation\">)</span>\n  self<span class=\"token punctuation\">.</span>item_emb <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Embedding<span class=\"token punctuation\">(</span>num_items<span class=\"token punctuation\">,</span> emb_size<span class=\"token punctuation\">)</span></code></pre></div>\n<p><code class=\"language-text\">nn.Embedding()</code> 에 넘겨지는 parameter는 크게 <strong>2가지</strong>가 있다. 1) 테이블 사이즈 (단어 및 데이터 갯수) 2) 임베딩 사이즈 (embedding vector  차원). <br></p>\n<p>영화에서 모델에 넣어서 학습할 데이터는 사용자 user와 영화 item이다. 이 두개에 대한 임베딩 테이블을 생성하기 위해서 인코딩 하며 중복없이 뽑아낸 user 와 item 리스트의 크기와 임베딩 사이즈를 결정해서 <code class=\"language-text\">nn.Embbeding()</code>을 호출한다. 그럼 임베딩 테이블이 생성되어 각각 user<em>emb 와 item</em>emb에 저장된다. <br></p>\n<h2 id=\"step2-linear-layer-생성---nnlinear\" style=\"position:relative;\"><a href=\"#step2-linear-layer-%EC%83%9D%EC%84%B1---nnlinear\" aria-label=\"step2 linear layer 생성   nnlinear permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Step2. Linear Layer 생성 - nn.Linear()</h2>\n<p>다음 코드에서는 Linear layer를 생성한다. 딥러닝의 핵심인 신경망(neural network) 층을 쌓아올려서 학습을 진행한다. 그때 필요한 신경망 층을 생성하는 역할을 한다. 딥러닝을 위한 신경망은 기본적으로 선형회귀분석을 기본으로 하기 때문에 선형변형 함수로 층을 쌓는다. <br></p>\n<p><img src=\"https://user-images.githubusercontent.com/63405904/110482886-7d8f0080-812c-11eb-9b12-6c65a734be69.png\" alt=\"image\"></p>\n<p>파이토치에서 제공하는 <a href=\"https://pytorch.org/docs/stable/nn.html#linear-layers\">document</a>를 살펴보면 위와 같은 선형변형 함수를 사용하는 것을 확인할 수 있다. 선형결합은 보존하는 선형변형 함수를 생성하고 원하는 <strong>in_feature</strong>와 <strong>out_feature</strong>의 사이즈를 parameter로 넘긴다. <br></p>\n<h3 id=\"-코드에서-layer-생성\" style=\"position:relative;\"><a href=\"#-%EC%BD%94%EB%93%9C%EC%97%90%EC%84%9C-layer-%EC%83%9D%EC%84%B1\" aria-label=\" 코드에서 layer 생성 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>> 코드에서 layer 생성</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\">#def __init__ 메소드 내:</span>\n\tself<span class=\"token punctuation\">.</span>lin1 <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>emb_size<span class=\"token operator\">*</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> n_hidden<span class=\"token punctuation\">)</span>\n  self<span class=\"token punctuation\">.</span>lin2 <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>n_hidden<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>위 코드는 입력 차원이 emb<em>size의 두배인 input sample에 대해서 n</em>hidden 사이즈 만큼의 차원으로 선형변형을 하는 linear layer 하나와, n_hidden 사이즈의 input sample에 대해서 1로 선형변형을 하는 linear layer 두개를 생성한다. <br></p>\n<h2 id=\"step3-모델-일반화---nndropout\" style=\"position:relative;\"><a href=\"#step3-%EB%AA%A8%EB%8D%B8-%EC%9D%BC%EB%B0%98%ED%99%94---nndropout\" aria-label=\"step3 모델 일반화   nndropout permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Step3. 모델 일반화 - nn.Dropout()</h2>\n<p>Dropout은 모델을 일반화 기법으로 일부 파라미터를 학습에 반영하지 않는 것이다. Validation과 test 시에는 적용하지 않고 train 시에 dropout을 적용하는데, 일종의 정규화 기법이라고 볼 수 있다. 모델을 학습할 때 과적합(overfitting)의 위험을 줄이고, 학습속도를 개선하는 문제를 해결하기 위한 방법이다. 모델을 학습할 때 지나치게 학습 데이터에 대한 높은 정확도를 보이기 보다, 범용적으로 사용될 수 있도록 overfitting 문제를 피하기 위해서 고안된 해결책 중 하나이다. 일반적으로 신경망의 층이 깊어지고, 학습률이 작을수록 overfitting이 될 가능성이 높다. <br></p>\n<p>이중 본 코드에서 사용하고 있는 모델 일반화의 방법은 드롭아웃 Dropout이다. 신경망 모델이 지나치게 복잡해질 때, 뉴런의 연결을 임의로 삭제하여 전달하지 않도록 떨어뜨리는 역할을 한다. 다만, 테스트를 할 때에는 모든 뉴런을 사용하기 때문에 반드시 학습시에만 드롭아웃을 적용해야 한다. <br></p>\n<p><img src=\"https://user-images.githubusercontent.com/63405904/110482706-47ea1780-812c-11eb-9908-5686512aae8c.png\" alt=\"image\"></p>\n<p>파이토치 <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout\">document</a>를 보면 <code class=\"language-text\">nn.torch</code> 모듈에서 드롭아웃 또한 지원을 한다. <br></p>\n<p><img src=\"https://user-images.githubusercontent.com/63405904/110482789-5fc19b80-812c-11eb-960c-8f7da3b2597f.png\" alt=\"image\"></p>\n<p>파이토치에 제공하는 도큐멘트를 살펴보면 학습시 무작위로 몇개의 뉴런들에 대해서 <em>p</em> 확률만큼  ‘zeros’ 시킨다고 나와있다. 이때 <em>p</em>는 parameter로 주어지는 확률 변수이고, default는 0.5이다. <code class=\"language-text\">forward</code>함수가 호출될 때마다 적용되도록 되어 있다. <br></p>\n<h3 id=\"-코드에서-dropout\" style=\"position:relative;\"><a href=\"#-%EC%BD%94%EB%93%9C%EC%97%90%EC%84%9C-dropout\" aria-label=\" 코드에서 dropout permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>> 코드에서 Dropout</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\">#def __init__ 메소드 내:</span>\n\tself<span class=\"token punctuation\">.</span>drop1 <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Dropout<span class=\"token punctuation\">(</span><span class=\"token number\">0.1</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>본 코드를 살펴보면 nn.torch 모둘에서 Dropout 함수를 호출하고 확률 변수를 0.1로 주었다. <br></p>\n<h2 id=\"step4-활성화함수---torchnnfunctionalrelu\" style=\"position:relative;\"><a href=\"#step4-%ED%99%9C%EC%84%B1%ED%99%94%ED%95%A8%EC%88%98---torchnnfunctionalrelu\" aria-label=\"step4 활성화함수   torchnnfunctionalrelu permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Step4. 활성화함수 - torch.nn.functional.relu()</h2>\n<p>다음 딥러닝 신경망 모델 구축에서 중요한 부분은 활성화 함수(Activation Function)이다. 활성화 함수는 최종출력 신호 후, 다음 뉴런으로 보낼지 말지를 결정하는 함수이다. 즉, 특정 뉴런이 다음 뉴런으로 신호를 보낼 때 입력신호의 어떠한 기준에 따라서 보내고 보내지 않는지를 결정하도록 하는 것이다. 딥러닝에서는 뉴런들을 다음 레이어로 전달할 때 비선형 함수를 통화시킨 후 전달하도록 하는데 이때 사용되는 함수가 활성화 함수이다. <br></p>\n<p>딥러닝 학습의 핵심은 이름에서 볼 수 있듯이 깊게 층을 쌓아서 그 층을 통과하면서 학습되는 것인데, 선형함수를 사용하게 되면 층을 깊게 하는 의미가 줄어들게 된다. 해당 설명은 [밑바닥부터 시작하는 딥러닝] 책의 한 부분을 인용하도록 하겠다. <br></p>\n<blockquote>\n<p>선형합수인 h(x)=cx를 활성화함수로 사용한 3층 네트워크를 떠올려 보세요. 이를 식으로 나타내면 y(x) = h(h(h(x)))가 됩니다. 이는 실은 y(x)=ax와 똑같은 식 입니다. a=c3이라고 하면 끝이죠. 즉, 은닉층이 없는 네트워크로 표현할 수 있습니다. 뉴럴네트워크에서 층을 쌓는 혜택을 얻고 싶다면 활성화 함수로는 반드시 비선형 함수를 사용해야 한다. </p>\n<p>-밑바닥부터 시작하는 딥러닝-</p>\n</blockquote>\n<p>이러한 역할을 하는 활성화 함수는 많은 종류가 있다. <strong>1) 시그모이드 함수 2) tanh 함수 3) ReLU 함수.</strong>  본 코드에서는 가장 많이 사용되는 활성화 함수인 ReLU 함수를 사용했다. <br></p>\n<p><img src=\"https://user-images.githubusercontent.com/63405904/110482937-8b448600-812c-11eb-9672-04dc7c7e5928.png\" alt=\"image\"></p>\n<p>ReLU 함수를 살펴보면 <span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"x > 0\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&gt;</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span> 이면 기울기가 1인 직선이고 <span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"x < 0\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">x</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.225em; padding-bottom: 0.372em;\">&lt;</span></span><span class=\"mjx-mn MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">0</span></span></span></span></span>이면 함수값이 0이 된다. 따라서 다른 활성화함수에 비해서 굉장히 간단하고 빠르다. 해당 함수는 양수에서는 Linear function 과 같은 모습을 보이지만 음수의 경우 0으로 버려지므로 non-linear 한 함수로 작동하여 layer를 깊게 쌓을 수 있는 장점을 가진다. <br></p>\n<h3 id=\"-코드에서-활성화함수\" style=\"position:relative;\"><a href=\"#-%EC%BD%94%EB%93%9C%EC%97%90%EC%84%9C-%ED%99%9C%EC%84%B1%ED%99%94%ED%95%A8%EC%88%98\" aria-label=\" 코드에서 활성화함수 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>> 코드에서 활성화함수</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\">#def forward 내</span>\n\tx <span class=\"token operator\">=</span> F<span class=\"token punctuation\">.</span>relu<span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>cat<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>U<span class=\"token punctuation\">,</span> V<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> dim<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>선형함수가 linear layer에 들어가기 전에 비선형 함수를 거친다. 위의 코드에서 F는 <code class=\"language-text\">torch.nn.funtional</code>모듈이며 모듈 내에 있는 <code class=\"language-text\">relu()</code>를 사용하고 있다. <br></p>\n<br>\n<br>\n<p><strong><small> [참고 자료]: <a href=\"https://wikidocs.net/64779\">https://wikidocs.net/64779</a>, <a href=\"https://tutorials.pytorch.kr/beginner/blitz/neural_networks_tutorial.html\">https://tutorials.pytorch.kr/beginner/blitz/neural_networks_tutorial.html</a>, <a href=\"https://pytorch.org/docs/\">https://pytorch.org/docs/</a>, <a href=\"https://yeomko.tistory.com/39\">https://yeomko.tistory.com/39</a>, <a href=\"https://reniew.github.io/12/\">https://reniew.github.io/12/</a>, <a href=\"https://eda-ai-lab.tistory.com/405\">https://eda-ai-lab.tistory.com/405</a>, <a href=\"https://jyoondev.tistory.com/65?category=823946\">https://jyoondev.tistory.com/65?category=823946</a>, <a href=\"https://sacko.tistory.com/45\">https://sacko.tistory.com/45</a></small></strong></p>\n<div class=\"table-of-contents\">\n<ul>\n<li><a href=\"#%EB%AA%A8%EB%8D%B8-%EC%A0%84%EC%B2%B4-%EC%BD%94%EB%93%9C\">모델 전체 코드</a></li>\n<li>\n<p><a href=\"#step1-%EC%9E%84%EB%B2%A0%EB%94%A9---nnembedding\">Step1. 임베딩 - nn.Embedding()</a></p>\n<ul>\n<li><a href=\"#-%EC%BD%94%EB%93%9C%EC%97%90%EC%84%9C-%EC%9E%84%EB%B2%A0%EB%94%A9\">> 코드에서 임베딩</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#step2-linear-layer-%EC%83%9D%EC%84%B1---nnlinear\">Step2. Linear Layer 생성 - nn.Linear()</a></p>\n<ul>\n<li><a href=\"#-%EC%BD%94%EB%93%9C%EC%97%90%EC%84%9C-layer-%EC%83%9D%EC%84%B1\">> 코드에서 layer 생성</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#step3-%EB%AA%A8%EB%8D%B8-%EC%9D%BC%EB%B0%98%ED%99%94---nndropout\">Step3. 모델 일반화 - nn.Dropout()</a></p>\n<ul>\n<li><a href=\"#-%EC%BD%94%EB%93%9C%EC%97%90%EC%84%9C-dropout\">> 코드에서 Dropout</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#step4-%ED%99%9C%EC%84%B1%ED%99%94%ED%95%A8%EC%88%98---torchnnfunctionalrelu\">Step4. 활성화함수 - torch.nn.functional.relu()</a></p>\n<ul>\n<li><a href=\"#-%EC%BD%94%EB%93%9C%EC%97%90%EC%84%9C-%ED%99%9C%EC%84%B1%ED%99%94%ED%95%A8%EC%88%98\">> 코드에서 활성화함수</a></li>\n</ul>\n</li>\n</ul>\n</div>","frontmatter":{"date":"August 22, 2020","title":"[머신러닝] 딥러닝 영화 개인화 추천 - Part.2","categories":"머신러닝","author":"코다","emoji":"🪄"},"fields":{"slug":"/movie-dlrm-2/"}},"prev":{"id":"1cfe8a3b-ad8f-5ccf-ae4a-4383087005d8","html":"<p>알고리즘에 대해서 배울 때 가장 먼저 다루는 부분이 바로 <strong>Time Complexity</strong> 이다. 기술이 발전하면서 메모리에 대한 부분은 상당 부분 해결이 되고 걱정하지 않아도 되는 부분이 되었다. 하지만 시간 복잡도 측면에서는 아무리 발전해도 부족한 부분이다. 왜냐하면 짧으면 짧을수록 더 좋기 때문이다. 따라서 알고리즘 강의를 들을 때에는 항상 Time Complexity에 대한 강의를 시작으로 배운다. 어떠한 문제에 대해서 여러가지 알고리즘을 사용하여 해결할 수 있을 때 무엇이 최적의 알고리즘인지를 판단하는 잣대는 해당 알고리즘으로 문제를 해결하는데 걸리는 시간이기 때문이다. 거기서 핵심적인 역할을 하는 두 theory에 대해서 <a href=\"https://www.geeksforgeeks.org/lower-and-upper-bound-theory/\">다음 글</a>의 내용을 번역 및 정리하면서 알아보자. <br></p>\n<p>Lower Bound와 upper Bound Theory는 어떠한 문제에 대한 가장 적은 복잡도를 가진 알고리즘을 선택하는데 핵심적인 역할을 한다. 구체적으로 이 이론들을 다루기 이전에 각각 Lower Bound와 Upper Bound가 무엇을 의미하는지 살펴보자. <br></p>\n<ul>\n<li>\n<p><strong>Lower Bound</strong> - <br></p>\n<p>L(n)이 알고리즘 A에 대한 수행 시간일 때, <span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"L(n) >= C*g(n)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">L</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.372em;\">&gt;<span class=\"mjx-charbox MJXc-TeX-main-R\" style=\"padding-bottom: 0.314em;\">=</span></span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;\">C</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.298em;\">∗</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.003em;\">g</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span>을 성립하는 <span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"C\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;\">C</span></span></span></span></span>가 있는 경우 <span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"g(n)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.003em;\">g</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span>은 A의 lower bound이다. 어떠한 알고리즘의 lower bound는 Big Omega 로 나타낸다. <br></p>\n</li>\n<li>\n<p><strong>Upper Bound</strong> - <br></p>\n<p>U(n)이 알고리즘 A에 대한 수행 시간일 때, <span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"L(n) <= C*g(n)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">L</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.372em;\">&lt;<span class=\"mjx-charbox MJXc-TeX-main-R\" style=\"padding-bottom: 0.314em;\">=</span></span></span><span class=\"mjx-mi MJXc-space3\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;\">C</span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.151em; padding-bottom: 0.298em;\">∗</span></span><span class=\"mjx-mi MJXc-space2\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.003em;\">g</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span>을 성립하는 <span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"C\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;\">C</span></span></span></span></span>가 있는 경우 <span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"g(n)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.003em;\">g</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span>은 A의 lower bound이다. 어떠한 알고리즘의 lower bound는 Big Oh(O) 로 나타낸다. <br></p>\n</li>\n</ul>\n<h2 id=\"1-lower-bound-theory\" style=\"position:relative;\"><a href=\"#1-lower-bound-theory\" aria-label=\"1 lower bound theory permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Lower Bound Theory:</h2>\n<p>Lower Bound Theory에 의하면 어떠한 알고리즘의 lower bound에 대하여 다른 어떠한 알고리즘도 랜덤한 input에 대하여 L(n)보다 적은 시간 복잡도를 가질 수 없다. 또한 다르게 말하면 모든 알고리즘들이 <strong>적어도 L(n)</strong> 만큼의 시간을 가질 수 밖에 없다. <br></p>\n<p><em>주의할 점: L(n)은 모든 알고리즘 중 최소의 복잡도를 나타낸다.</em><br></p>\n<p>Lower Bound 는 그 어던 알고리즘에 있어서도 매우 중요하다. Lower Bound를 계산한 후에, 특정 알고리즘의 복잡도를 계산하여 L(n)과 같다면 해당 알고리즘이 최적의 알고리즘이라는 것을 알 수 있다. 이 글에서 우리는 어떠한 알고리즘의 lower bound를 찾는 방법들에 대해서 다루어 볼 것이다. <br></p>\n<p>명심해야 하는 것은 언제나 우리의 가장 중요한 목적이 <strong>최적의 알고리즘</strong>을 구하는 것이라는 것이다. 여기서 최적의 알고리즘이라고 함은 해당 알고리즘의 Upper Bound 가 해당 문제의 Lower Bound와 같은(U(n)=L(n)) 경우이다. <em>Merge sort</em>를 통해서 optimal algorithm을 살펴보자. <br></p>\n<h3 id=\"trivial-lower-bound--\" style=\"position:relative;\"><a href=\"#trivial-lower-bound--\" aria-label=\"trivial lower bound   permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Trivial Lower Bound -</h3>\n<p>Lower bound를 찾는 가장 쉬운 방법이다. 이 방법은 Lower bound가 문제의 input의 개수와 output의 개수로 쉽게 알 수 있다고 하는 Trivial Lower Bound 방법이다. <br></p>\n<h4 id=\"예시-multiplication-of-nn-matrix\" style=\"position:relative;\"><a href=\"#%EC%98%88%EC%8B%9C-multiplication-of-nn-matrix\" aria-label=\"예시 multiplication of nn matrix permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>예시: Multiplication of n*n matrix</h4>\n<ul>\n<li>Input: 2개의 행렬에 대해 <span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"2n^2\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span></span>개</li>\n<li>Output: 1 개의 n*n 행렬, <span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"n^2\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span></span></span></span> 개</li>\n</ul>\n<p>위의 input/output의 숫자를 보면 쉽게 lower bound가 <span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"O(n^2)\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.519em; padding-bottom: 0.298em;\">O</span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">(</span></span><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mn\" style=\"\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span></span><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">)</span></span></span></span></span>라는 것을 알 수 있다. <br></p>\n<h3 id=\"computational-model--\" style=\"position:relative;\"><a href=\"#computational-model--\" aria-label=\"computational model   permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Computational Model -</h3>\n<p>이 방법을 비교를 하는 모든 알고리즘에 대해서 사용할 수 있다. 예를 들어, sorting 문제의 경우 각 원소들을 비교하고 배열을 해야한다. 탐색하는 문제 또한 비슷하다. 예시를 통해서 해당 문제들의 lower bound를 구하는 법에 대해서 살펴보자. <br></p>\n<h3 id=\"ordered-searching--\" style=\"position:relative;\"><a href=\"#ordered-searching--\" aria-label=\"ordered searching   permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Ordered Searching -</h3>\n<p>이미 정렬이 되어 있는 리스트에 대해서 탐색을 하는 경우이다. <br></p>\n<h3 id=\"example-1-linear-search\" style=\"position:relative;\"><a href=\"#example-1-linear-search\" aria-label=\"example 1 linear search permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Example 1: Linear Search</h3>\n<p>처음부터 시작하여 차례로 각 element를 순회하며 해당 원소가 찾던 원소인지 확인한다. </p>\n<h3 id=\"example-2-binary-search\" style=\"position:relative;\"><a href=\"#example-2-binary-search\" aria-label=\"example 2 binary search permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Example 2: Binary Search</h3>\n<p>중간에 있는 것과 비교하여 찾고자 하는 숫자가 클 경우, 반의 오른쪽 부분을, 작을 경우 반의 왼쪽 부분을 나누어서 탐색한다. </p>\n<h3 id=\"calculation-the-lower-bound\" style=\"position:relative;\"><a href=\"#calculation-the-lower-bound\" aria-label=\"calculation the lower bound permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Calculation the lower bound:</h3>\n<p>비교하는 최대 횟수는 n이고, 리스트의 tree에 총 k levels이 있다고 한다면..</p>\n<ol>\n<li>Node의 갯수는 <span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"2^k-1\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.591em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">k</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">−</span></span><span class=\"mjx-mn MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span></li>\n<li><span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"2^k -1\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-msubsup\"><span class=\"mjx-base\"><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span></span><span class=\"mjx-sup\" style=\"font-size: 70.7%; vertical-align: 0.591em; padding-left: 0px; padding-right: 0.071em;\"><span class=\"mjx-mi\" style=\"\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">k</span></span></span></span><span class=\"mjx-mo MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.298em; padding-bottom: 0.446em;\">−</span></span><span class=\"mjx-mn MJXc-space2\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">1</span></span></span></span></span>에 대하여 worst case의 경우 upper bound 개수인 n </li>\n<li>각 레밸에서 1번 비교를 하니, 비교하는 횟수는 <span class=\"mjx-chtml\"><span class=\"mjx-math\" aria-label=\"k>=|log2n|\"><span class=\"mjx-mrow\" aria-hidden=\"true\"><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">k</span></span><span class=\"mjx-mo MJXc-space3\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.077em; padding-bottom: 0.372em;\">&gt;<span class=\"mjx-charbox MJXc-TeX-main-R\" style=\"padding-bottom: 0.314em;\">=</span></span></span><span class=\"mjx-texatom MJXc-space3\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">|</span></span></span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.446em; padding-bottom: 0.298em;\">l</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">o</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.003em;\">g</span></span><span class=\"mjx-mn\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.372em; padding-bottom: 0.372em;\">2</span></span><span class=\"mjx-mi\"><span class=\"mjx-char MJXc-TeX-math-I\" style=\"padding-top: 0.225em; padding-bottom: 0.298em;\">n</span></span><span class=\"mjx-texatom\"><span class=\"mjx-mrow\"><span class=\"mjx-mo\"><span class=\"mjx-char MJXc-TeX-main-R\" style=\"padding-top: 0.446em; padding-bottom: 0.593em;\">|</span></span></span></span></span></span></span></li>\n</ol>\n<p>따라서 비교 문제에 있어서 n개의 원소를 가질 경우 복잡도는 log(n) 보다 작을 수 없다. 따라서 시간복잡도를 (log n)을 가진 binary serach가 최적화된 알고리즘이라고 판단할 수 있다. </p>\n<h2 id=\"2-upper-bound-theory\" style=\"position:relative;\"><a href=\"#2-upper-bound-theory\" aria-label=\"2 upper bound theory permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. Upper Bound Theory</h2>\n<p>Upper Bound Theory는 해당 문제를 푸는데 최대 U(n)만큼이 시간이 뜬다는 것이다. 주로 worst case input인 경우 Upper Bound를 알 수 있다. <br></p>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#1-lower-bound-theory\">1. Lower Bound Theory:</a></p>\n<ul>\n<li>\n<p><a href=\"#trivial-lower-bound--\">Trivial Lower Bound -</a></p>\n<ul>\n<li><a href=\"#%EC%98%88%EC%8B%9C-multiplication-of-nn-matrix\">예시: Multiplication of n*n matrix</a></li>\n</ul>\n</li>\n<li><a href=\"#computational-model--\">Computational Model -</a></li>\n<li><a href=\"#ordered-searching--\">Ordered Searching -</a></li>\n<li><a href=\"#example-1-linear-search\">Example 1: Linear Search</a></li>\n<li><a href=\"#example-2-binary-search\">Example 2: Binary Search</a></li>\n<li><a href=\"#calculation-the-lower-bound\">Calculation the lower bound:</a></li>\n</ul>\n</li>\n<li><a href=\"#2-upper-bound-theory\">2. Upper Bound Theory</a></li>\n</ul>\n</div>","frontmatter":{"date":"September 04, 2020","title":"[번역] Lower and Upper Bound Theory","categories":"알고리즘","author":"코다","emoji":"🤹‍♀️"},"fields":{"slug":"/low-upper-bound/"}},"site":{"siteMetadata":{"siteUrl":"https://yjksw.github.io","comments":{"utterances":{"repo":"yjksw/yjksw.github.io"}}}}},"pageContext":{"slug":"/bin-search-bound/","nextSlug":"/movie-dlrm-2/","prevSlug":"/low-upper-bound/"}},"staticQueryHashes":["1073350324","2938748437"]}